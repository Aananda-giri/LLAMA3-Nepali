{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10391038,"sourceType":"datasetVersion","datasetId":6433294},{"sourceId":216333482,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* GPU p100\n* presistance: Files only\n* secrets: HF_TOKEN\n* internet: on\n* dataset: https://www.kaggle.com/datasets/aanandagiri/llama3-nepali","metadata":{}},{"cell_type":"code","source":"!cp -r /kaggle/input/llama3-nepali/* ./\n!ls /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:19:27.670164Z","iopub.execute_input":"2025-01-07T14:19:27.670620Z","iopub.status.idle":"2025-01-07T14:19:28.049998Z","shell.execute_reply.started":"2025-01-07T14:19:27.670586Z","shell.execute_reply":"2025-01-07T14:19:28.048763Z"}},"outputs":[{"name":"stdout","text":"3_pretrain.py\t\t\t     functions.py\t   README.md\n4.5_download_checkpoint_from_hub.py  hf_cache\t\t   test\n4_push_latest_checkpoint_to_hub.py   model_checkpoints\t   tokenizer.json\ncleaned_bhagavad_gita_data.txt\t     previous_chapters.py\ndebug_dataloaders.py\t\t     __pycache__\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install --upgrade transformers --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:19:29.368356Z","iopub.execute_input":"2025-01-07T14:19:29.368733Z","iopub.status.idle":"2025-01-07T14:19:47.060285Z","shell.execute_reply.started":"2025-01-07T14:19:29.368708Z","shell.execute_reply":"2025-01-07T14:19:47.059076Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!rm -rf model_checkpoints/*\n!ls -l --block-size=M model_checkpoints","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:19:47.061886Z","iopub.execute_input":"2025-01-07T14:19:47.062236Z","iopub.status.idle":"2025-01-07T14:19:47.591335Z","shell.execute_reply.started":"2025-01-07T14:19:47.062203Z","shell.execute_reply":"2025-01-07T14:19:47.590353Z"}},"outputs":[{"name":"stdout","text":"total 0M\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download latest model checkpoint from hub \n# <replace checkpoint_name with latest checkpoint name>\n\n!python3 4.5_download_checkpoint_from_hub.py \\\n  --checkpoint_name model_checkpoints/model_pg_10000_steps.pth \\\n  --destination /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:19:47.593618Z","iopub.execute_input":"2025-01-07T14:19:47.593935Z","iopub.status.idle":"2025-01-07T14:20:21.068631Z","shell.execute_reply.started":"2025-01-07T14:19:47.593912Z","shell.execute_reply":"2025-01-07T14:20:21.067570Z"}},"outputs":[{"name":"stdout","text":"-------------------------------------------------- \nDownloading checkpoint: \"model_checkpoints/model_pg_10000_steps.pth\" to folder: \"/kaggle/working\"...\n --------------------------------------------------\nmodel_pg_10000_steps.pth: 100%|████████████| 1.38G/1.38G [00:32<00:00, 42.3MB/s]\nCheckpoint downloaded to: /kaggle/working/model_checkpoints/model_pg_10000_steps.pth\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# !rm -rf model_checkpoints/*\n!ls -l --block-size=M model_checkpoints","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:20:21.070143Z","iopub.execute_input":"2025-01-07T14:20:21.070552Z","iopub.status.idle":"2025-01-07T14:20:21.190201Z","shell.execute_reply.started":"2025-01-07T14:20:21.070515Z","shell.execute_reply":"2025-01-07T14:20:21.189057Z"}},"outputs":[{"name":"stdout","text":"total 1316M\n-rw-r--r-- 1 root root 1316M Jan  7 14:20 model_pg_10000_steps.pth\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!python 3_pretrain.py \\\n--n_epochs 1 \\\n--batch_size 30 \\\n--output_dir model_checkpoints \\\n--eval_freq 1000 \\\n--save_ckpt_freq_steps 1000 \\\n--debug False \\\n--peak_lr 1e-4 \\\n--initial_lr 1e-5 \\\n--min_lr 1e-5 \\\n--resume_from_previous_training True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:24:01.333803Z","iopub.execute_input":"2025-01-07T14:24:01.334052Z"}},"outputs":[{"name":"stdout","text":"---------------------\nDEBUG MODE=False\n---------------------\nIterableDatasetDict({\n    train: IterableDataset({\n        features: ['input_ids,target_ids'],\n        num_shards: 1\n    })\n    test: IterableDataset({\n        features: ['input_ids,target_ids'],\n        num_shards: 1\n    })\n})\nNew RoPE theta (i.e. LLAMA32_CONFIG[\"rope_base\"]): 31250.0\ncompiling the model... (takes a ~minute)\nThe following is expected to print True to confirm buffers are reused instead of being (wastefully) recreated:\nTrue\nTrue\nTrue\nTotal number of parameters: 228,258,816\n\nTotal number of unique parameters: 177,052,672\nfloat32 (PyTorch default): 1.70 GB\nbfloat16: 0.85 GB\ndevice: cuda\n\n\nargs.resume_from_previous_training: True\n\n\nLoading existing model: model_checkpoints/model_pg_10000_steps.pth\n----------------------------------------------------------------------\ntrain_losses: <class 'list'>  len: 11\nval_losses: <class 'list'>  len: 11\ntrack_tokens_seen: <class 'list'>  len: 11\ntrack_lrs: <class 'list'>  len: 10001\nprevious epochs: <class 'int'> 0\nprevious global step: 10001 \n previous epochs: 0\n\n----------------------------------------------------------------------\nlen. train_loader: 159368\nlen.val_loader: 17707\nTraining ...\ntotal_steps: 159368\n warmup_steps: 31873\n constant min_lr after: 143431 steps\npush to hub once every 11.5 hours i.e. 41400.0 seconds..\n\n----------------------------------------------------------------------\n\n\n----------------------------------------------------------------------\n resuming from global_step : 10001 \n train_loader_index: 10001 \n len_train_loader: 159368 \n Time: 2 minutes, 38 seconds\n----------------------------------------------------------------------\n/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla P100-PCIE-16GB does not support bfloat16 compilation natively, skipping\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla P100-PCIE-16GB does not support bfloat16 compilation natively, skipping\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla P100-PCIE-16GB does not support bfloat16 compilation natively, skipping\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla P100-PCIE-16GB does not support bfloat16 compilation natively, skipping\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla P100-PCIE-16GB does not support bfloat16 compilation natively, skipping\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# import os\n# from kaggle_secrets import UserSecretsClient\n# secret_label = \"your-secret-label\"\n\n# os.environ['KAGGLE_KEY'] = UserSecretsClient().get_secret('HF_TOKEN')\n# os.environ['KAGGLE_USERNAME'] = UserSecretsClient().get_secret('KAGGLE_USERNAME')\n# !mkdir test/\n# !kaggle kernels output aanandagiri/llama3-nepali-notebook -p test/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:18:31.394221Z","iopub.execute_input":"2025-01-07T14:18:31.394663Z","iopub.status.idle":"2025-01-07T14:18:31.601080Z","shell.execute_reply.started":"2025-01-07T14:18:31.394633Z","shell.execute_reply":"2025-01-07T14:18:31.600012Z"}},"outputs":[],"execution_count":5}]}